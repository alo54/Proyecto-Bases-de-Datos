# Proyecto: AnÃ¡lisis de accidentes de trÃ¡fico en Chicago

## Integrantes
- Regina Cabral
- Alondra Valdivia
- Gabriel Navarro
- Iker Navarro
- Ricardo LimÃ³n

## DescripciÃ³n general 

El conjunto de datos de â€œAccidentes de TrÃ¡fico de Chicagoâ€ es un registro pÃºblico que contiene informaciÃ³n detallada de cada choque reportable dentro de los lÃ­mites de la ciudad y bajo la jurisdicciÃ³n del Departamento de PolicÃ­a de Chicago (CPD). Incluye circunstancias, causas y consecuencias de los incidentes viales, desde daÃ±os materiales menores hasta colisiones fatales.

Para este proyecto se usarÃ¡n los datasets pÃºblicos: **Traffic Crashes - Crashes**, **Traffic Crashes - Vehicles** y **Traffic Crashes - People**, obtenidos del [Chicago Open Data Portal](https://data.cityofchicago.org/).  

Los datos son recolectados diariamente por el CPD a travÃ©s del sistema **E-Crash**, con el objetivo de mantener registros oficiales, apoyar iniciativas de seguridad pÃºblica y permitir al Departamento de Transporte de Chicago (CDOT) identificar Ã¡reas de riesgo y evaluar proyectos de seguridad vial.

**Enlaces a los datasets:**
- [Crashes](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if/about_data)  
- [Vehicles](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Vehicles/68nd-jvt3/about_data)  
- [People](https://data.cityofchicago.org/Transportation/Traffic-Crashes-People/u6pd-qa9d/about_data)  

---

## Resumen de datos

| Dataset | Tuplas | Atributos |
|:-------:|:------:|:---------:|
| Crashes | 989,000 | 48 |
| Vehicles | 2,020,000 | 71 |
| People | 2,170,000 | 29 |

> El conjunto solo incluye choques donde el CPD fue la agencia respondedora; accidentes en autopistas interestatales y algunas carreteras limÃ­trofes estÃ¡n excluidos.

---

## Atributos 

### Traffic Crashes - Crashes

| Atributo | Tipo | DescripciÃ³n |
|:---------|:----:|:-----------|
| crash_record_id | Texto | Identificador Ãºnico del accidente |
| crash_date | Fecha/Hora | Fecha y hora del accidente |
| crash_hour | NumÃ©rico | Hora del accidente |
| crash_day_of_week | NumÃ©rico | DÃ­a de la semana (1=domingo) |
| crash_month | NumÃ©rico | Mes del accidente |
| posted_speed_limit | NumÃ©rico | LÃ­mite de velocidad |
| lane_cnt | NumÃ©rico | NÃºmero de carriles |
| traffic_control_device | CategÃ³rico | Dispositivo de control de trÃ¡fico |
| device_condition | CategÃ³rico | Estado del dispositivo |
| weather_condition | CategÃ³rico | Condiciones climÃ¡ticas |
| lighting_condition | CategÃ³rico | Condiciones de iluminaciÃ³n |
| first_crash_type | CategÃ³rico | Tipo de primera colisiÃ³n |
| crash_type | CategÃ³rico | Severidad general del accidente |
| prim_contributory_cause | CategÃ³rico | Causa primaria del accidente |
| sec_contributory_cause | CategÃ³rico | Causa secundaria |
| latitude / longitude | NumÃ©rico | Coordenadas geogrÃ¡ficas |
| street_name / street_no / street_direction | Texto | DirecciÃ³n del accidente |
| num_units | NumÃ©rico | NÃºmero de unidades involucradas |
| injuries_total / fatal / incapacitating / non_incapacitating / no_indication / unknown | NumÃ©rico | Total y tipo de lesiones |
| most_severe_injury | CategÃ³rico | LesiÃ³n mÃ¡s grave observada |
| report_type | Texto | Tipo de reporte administrativo |
| photos_taken_i / statements_taken_i / dooring_i / work_zone_i / workers_present_i | CategÃ³rico | Indicadores de observaciÃ³n |

---

### Traffic Crashes - Vehicles

| Atributo | Tipo | DescripciÃ³n |
|:---------|:----:|:-----------|
| crash_record_id | Texto | Relaciona con Crashes |
| vehicle_id / crash_unit_id / unit_no | NumÃ©rico | Identificadores de vehÃ­culo |
| vehicle_type / make / model | CategÃ³rico | Tipo, marca y modelo |
| vehicle_year | NumÃ©rico | AÃ±o del modelo |
| occupant_cnt / num_passengers | NumÃ©rico | Cantidad de ocupantes |
| unit_type / maneuver / travel_direction / towed_i / fire_i / exceed_speed_limit_i | CategÃ³rico | CaracterÃ­sticas y condiciones del vehÃ­culo |
| cargo_body_type / load_type / hazmat_present_i | CategÃ³rico | InformaciÃ³n de carga y materiales peligrosos |
| crash_date | Fecha/Hora | Fecha y hora del accidente |

---

### Traffic Crashes - People

| Atributo | Tipo | DescripciÃ³n |
|:---------|:----:|:-----------|
| person_id | Texto | Identificador de la persona (P=pasajero, O=otro) |
| crash_record_id | Texto | Relaciona con Crashes |
| vehicle_id | Texto | Relaciona con Vehicles |
| person_type | CategÃ³rico | Conductor, pasajero, peatÃ³n o ciclista |
| age | NumÃ©rico | Edad de la persona |
| sex | CategÃ³rico | GÃ©nero |
| seat_no | CategÃ³rico | PosiciÃ³n en el vehÃ­culo |
| drivers_license_state / drivers_license_class | CategÃ³rico | InformaciÃ³n de licencia de conducir |
| safety_equipment / airbag_deployed / ejection | CategÃ³rico | Equipo de seguridad y resultados del accidente |
| injury_classification | CategÃ³rico | Severidad de lesiÃ³n |
| hospital / ems_agency / ems_run_no | Texto | AtenciÃ³n mÃ©dica y transporte |
| driver_action / driver_vision / physical_condition | CategÃ³rico | Comportamiento y condiciÃ³n del conductor |
| pedpedal_action / pedpedal_visibility / pedpedal_location | CategÃ³rico | AcciÃ³n y ubicaciÃ³n de peatÃ³n/ciclista |
| bac_result / bac_result_value | CategÃ³rico / NumÃ©rico | Prueba de alcohol en sangre |
| cell_phone_use | CategÃ³rico | Uso de celular al momento del accidente |
| crash_date | Fecha/Hora | Fecha y hora del accidente |

---

## Objetivo del Proyecto

El objetivo del anÃ¡lisis es identificar **factores de riesgo** y **patrones de accidentes** para proponer medidas que mejoren la seguridad vial.  

**Enfoques posibles:**
- **Seguridad Vial:** Analizar clima, hora, tipo de vehÃ­culo y condiciones de la vÃ­a sobre la severidad de lesiones.  
- **Espacial:** Identificar calles e intersecciones con mayor concentraciÃ³n de accidentes (*hotspots*).  
- **Temporal:** Detectar tendencias por hora, dÃ­a de la semana y estaciÃ³n del aÃ±o.  
- **Comportamiento de Conductores:** Evaluar infracciones, distracciones y consumo de alcohol.  
- **Multidimensional:** Cruzar atributos como tipo de vehÃ­culo, hora y clima para anÃ¡lisis mÃ¡s completos.

---

## Consideraciones Ã‰ticas

- **ProtecciÃ³n de la Privacidad:** El dataset estÃ¡ anonimizado. No se deben intentar re-identificar personas.  
- **PrecisiÃ³n y Limitaciones:** Los datos pueden contener errores o sesgos; el anÃ¡lisis debe considerarlos.  
- **Equidad y Desigualdad Social:** Las fatalidades no se distribuyen uniformemente; se debe tener cuidado de no reforzar prejuicios.  
- **ComunicaciÃ³n Responsable:** Presentar hallazgos con contexto; un alto nÃºmero de accidentes puede reflejar mayor trÃ¡fico y no necesariamente un diseÃ±o peligroso de la vÃ­a.

---
## Limpieza de datos
El proceso de limpieza de datos se llevÃ³ a cabo de manera incremental y sistemÃ¡tica sobre cada una de las tablas creadas, con el objetivo de garantizar consistencis, eliminar valores invÃ¡lidos y estandarizar los formatos antes de realizar anÃ¡lisis y consultas complejas. 

Uno de los principales problemas detectados fue a presencia de valores nulos no explÃ­citos, es decir, cadenas vacÃ­as (`''`) o valores de texto que representaban ausencia de informaciÃ³n. Para solucionarlo, se aplicaron funciones como `NULLIF`, `BTRIM`  y `COALESCE`, tranformando estos registros en valores `NULL` reales dentro de PostgresSQL.

En la tabla **`people`** se normalizaron atributos como **`people_type`**, **`sex`**, **`safety_equipment`**,**`airbag_deployed`** e **`injury_classification`**, eliminando cadenas vacÃ­as y estandarizando los valores. De manera similar, en la tabla **`vehicle`** se limpiaron campos textuales como **`unit_type`**, **`make`**, **`model`** y **`vehicle_type`**.

Para las tablas especializadas de vehiculos (**`vehicle_models`**, **`vehicle_maneuvers`**, **`vehicle_violations`**) se aplicaron transformaciones adicionales para eliminar espacios innecesarios y corregir valores invÃ¡lidos, garantizando que los atributos categÃ³ricos fueran consistentes y utilizables en anÃ¡lisis posteriores. 

En el caso de **`driver_info`**, se realizÃ³ una limpieza mÃ¡s exhaustiva debido a la variedad de valores en atributos como **`driver_action`**, **`driver_vision`**, **`physical_condition`** y **`drivers_license_class`**. Se eliminaron caracteres no vÃ¡lidos, se estandarizÃ³ el uso de mayÃºsculas y se validaron las expresiones mediante expresiones regulares para asegurar la coherencia de los registros. 

Por Ãºltimo, en **`crash_injuries`** se detectÃ³ la presencia de valores nulos en campos nÃºmericos crÃ­ticos. Para evitar incosistencias en los cÃ¡lculos, los valores fueron sustituidos por ceros utilizando **`COALESCE`**, bajo el supuesto de que la ausencia de registros implicaba la inexistencia de lesiones de ese tipo. 

Al concluir este proceso, se obtuvo un conjunto de tablas con datos limpios, correctamente tipados y coherente entre sÃ­, listos para su anÃ¡lisis y para garantizar integridad durante la normalizaciÃ³n. 

### ReplicaciÃ³n
Esta secciÃ³n describe cÃ³mo reproducir el proceso de limpieza de la base de datos a partir de los archivos originales, utilizando Python y Jupyter Notebooks.

1. Requisitos
Para ejecutar los scripts de limpieza es necesario contar con:
* Python 3.9 o superior
* Jupyter Notebook
* LibrerÃ­as de Python:
    * pandas
    * numpy
 
2. Estructura relevante del proyecto
Los notebooks responsables del proceso de limpieza son los siguientes:
	- trim_crashes.ipynb
	- trim_vehicles.ipynb
	- Pedestrian_info.ipynb
	- Crash_classification.ipnynb
	- limpieza_people_people.ipynb
	-  limpieza_people_driver_info.ipynb
	-  crash_injuries_build.ipynb
    -  vehicles_buildcsv.ipynb
	-  LimpiezaCrashes.ipynb

Cada notebook se encarga de limpiar y estandarizar una o mÃ¡s tablas especÃ­ficas del modelo de datos.

3. Orden de ejecuciÃ³n
Para reproducir correctamente la limpieza, los notebooks deben ejecutarse en el siguiente orden:
	1. trim_crashes.ipynb
       Limpieza inicial del conjunto de datos Traffic_Crashes_Crashes
	2. trim_vehicles.ipynb
	   Limpieza inicial del conjunto de datos Traffic_Crashes_Vehicles
	3. limpieza_people_people.ipynb
       NormalizaciÃ³n y estandarizaciÃ³n de atributos de personas involucradas.
	4. limpieza_people_driver_info.ipynb
       Limpieza de informaciÃ³n especÃ­fica de conductores
	5. crash_injuries_build.ipynb
       Limpieza y construcciÃ³n de variables relacionadas con lesiones
	6. LimpiezaCrashes.ipynb
       Limpieza y normalizaciÃ³n de crashes
	7. Pedestrian_info.ipynb
       Limpieza y normalizaciÃ³n de atributos relacionados con peatones
	8. Crash_classification 
	   Limpieza de crash_classification
    9. vehicles_buildcsv.ipynb
       Limpieza y normalizaciÃ³n de vehicles
---
## NormalizaciÃ³n de datos

La estructura final del modelos de datos refleja un proceso de normalizaciÃ³n que alcanza la cuarta forma normal (4NF), al eliminar redundancias y asegurar que cada atributo depende Ãºnicamente de la llave primaria de su tabla. 

Cada tabla representa una entidad claramente definida: 
- **Crashes** : informaciÃ³n base del accidente.
- **Crash_date**, **crash_circumstances**, **crash_injuries**, **crash_classification**: descomposiciÃ³n funcional del accidente en subconjuntos lÃ³gicos de atributos.
- **Vehicle** y sus tablas asociadas: modelan de forma independiente a cada vehÃ­culo involucrado.
- **People** y driver_info: separan informaciÃ³n general de personas de informacion exclusiva de conductores.

Las dependencias funcionales principales observadas incluyen: 
- `{crash_record_id} â†’` atributos del accidente y sus subcomponentes.
- `{vehicle_id} â†’` atributos propios del vehÃ­culo
- `{person_id} â†’` atributos personales y, en el caso de conductores, atributos especÃ­ficos de conducciÃ³n.

La separaciÃ³n de informaciÃ³n permitiÃ³ eliminar duplicidad de datos, reducir anomalÃ­as de actualizaciÃ³n y facilitar la extensiÃ³n futura del modelo. El uso de llaves forÃ¡neas asegura integridad referencial entre las entidades, mientras que la ausencia de dependencias parciales no transitivas en las tablas confirma el cumplimiento de los criterios de normalizaciÃ³n establecidos. 

Como resultado, se obtuvo un esquema relacional robusto, flexible y alineado con las mejores prÃ¡cticas de diseÃ±o de base de datos relacionales para anÃ¡lisis de eventos complejos como accidentes de trÃ¡nsito. 

![Diagrama Entidad-RelaciÃ³n del modelo de datos](figures/erd.JPG)

El proceso comenzÃ³ con la creaciÃ³n de la tabla principal **'crashes'**, la cual concentra la informaciÃ³n base de cada accidente, identificada de manera Ãºnica por el atributo **'crash_record_id'**. Esta tabla almacena informaciÃ³n temporal y espacial del evento, como la fecha del accidente, coordenadas geogrÃ¡ficas y la vialidad asociada. 

Posteriormente, a partir del identificados del accidente, se crearon tablas auxiliares especializdas que capturan distintos aspectos del mismo evento: 
-**'crash_date'**, que descompone la fecha del accidente en dÃ­a de la semana y mes facilitando anÃ¡lisis temporales. 
-**'crash_circumstances'**, que almacena condiciones del entorno vial y del accidente (dispositivos de control de trÃ¡fico, clima, iluminaciÃ³n, nÃºmero de carriles, velocidad permitida, etc.).
-**'crash_injuties'**, que concentra la informaciÃ³n relacionada con lesiones resultantes del accidente.
-**'crash_classification'**, que clasifica el tipo de choque, causas contribuyentes y si se tratÃ³ de un evento de tipo hit-and-run

Todas estas tablas mantienen una relaciÃ³n uno a uno con la tabla **'crashes'** mediante el uso de llaves forÃ¡neas sobre **'crash_record_id'**, garantizando coherencia referencial desde la etapa inicial de carga. 

De forma anÃ¡loga, se creÃ³ la entidad **'vehicle'**, que representa a cada vehÃ­culo involucrado en un accidente. Cada vehÃ­culo se identifica mediante **'vehicle_id'**, y se relaciona con un accidente especÃ­fico a travÃ©s de **'crash_record_id'**. A partir de esta tabla se derivaron estructuras adicionales para capturar caracterÃ­sticas especÃ­ficas:
-**'vehicle_models'**, para informaciÃ³n estructural del vehÃ­culo.
-**'vehicle_maneuvers'**, para registrar la maniobra realizada al momento del accidente. 
-**'vehicle_violations'**, que indica infracciones o condiciones especiales del vehÃ­culo. 

Finalmente, se creÃ³ la tabla **'people'**, que contiene la informaciÃ³n de las personas involucradas en los accidentes, junto con la tabla **'driver_info'**, que especializa la infomaciÃ³n Ãºnicamnete para aquellas personas que actuaban como conductores. Estas tablas se relacionan tanto con **'crashes'** como con **'vehicle'**, permitiendo modelar adecuadamente la participaciÃ³n de cada individuo en el evento. 

Este diseÃ±o inicial permitiÃ³ contar desde el incio con una base de datos estructurada, coherente y preparada para un proceso sistemÃ¡tico de limpieza y normalizaciÃ³n

## Carga inicial de datos y analisis preliminar
Antes de realizar cualquier proceso de anÃ¡lisis, fue necesario crear la estructura de la base de datos y cargar la informaciÃ³n limpia en un conjunto de tablas relacionales. Este proceso se realizÃ³ en dos etapas: creaciÃ³n del esquema y carga de datos desde archivos CSV

1. CreaciÃ³n de las tablas (DDL)
La estructura completa de la base de datos se define en el archivo: 
```sql
traffic_crashes_ddl.sql
```
Este archivo contiene las sentencias DROP TABLE IF EXISTS y CREATE TABLE necesarias para crear todas las tablas del modelo relacional, incluyendo:
	* crashes
	* crash_date
	* crash_circumstances
	* crash_classification
	* crash_injuries
	* vehicle
	* vehicle_models
	* vehicle_maneuvers
	* vehicle_violations
	* people
	* driver_info
Las relaciones entre tablas se establecen mediante llaves forÃ¡neas basadas principalmente en los identificadores crash_record_id, vehicle_id y person_id, garantizando la integridad referencial desde el inicio.
Para crear las tablas, el archivo traffic_crashes_ddl.sql debe ejecutarse completamente en la base de datos antes de cargar cualquier informaciÃ³n.

2. Carga de datos desde archivos CSV
Una vez creadas las tablas, los datos fueron cargados a partir de archivos CSV generados durante el proceso de limpieza en Python.
La carga se realizÃ³ utilizando TablePlus, siguiendo estos pasos para cada tabla:
	1. Abrir la conexiÃ³n a la base de datos en TablePlus.
	2. Seleccionar la tabla destino (previamente creada).
	3. Hacer clic derecho sobre la tabla y elegir: Import â†’ From CSV
	4. Seleccionar el archivo CSV correspondiente.
	5. Verificar que las columnas del CSV coincidan con la estructura de la tabla.
	6. Ejecutar la importaciÃ³n.
Este proceso se repitiÃ³ para cada tabla del modelo, asegurando que:
* Las tablas principales se cargaran antes que las tablas dependientes.
* Las llaves forÃ¡neas existieran previamente para evitar errores de integridad.

- Limpieza final directamente en SQL
DespuÃ©s de completar la carga de los datos desde los archivos CSV, se realizÃ³ una Ãºltima etapa de limpieza directamente sobre la base de datos utilizando sentencias SQL, con el objetivo de asegurar la consistencia de los valores nulos.
En particular, se detectÃ³ que algunos campos de tipo texto contenÃ­an cadenas vacÃ­as ('') en lugar de valores NULL, lo cual podÃ­a generar inconsistencias en consultas posteriores y en el uso de funciones de agregaciÃ³n.
Para corregir esto, se ejecutÃ³ el archivo:
```sql
limpieza_ddl.sql
```

## AnÃ¡lisis de datos a travÃ©s de consultas SQL
Realizamos varias consultas de SQL para el anÃ¡lisis de la base de datos, descubriendo informaciÃ³n valiosa para identificar y concluir acerca de factores de riesgo y patrones de accidentes.

### I. Condiciones viales
1. Accidentes por defectos de la vÃ­a (road deffects)

```sql
SELECT
    cc.road_defect,
    COUNT(DISTINCT c.crash_record_id) AS total_crashes
FROM crashes c
JOIN crash_circumstances cc
    ON c.crash_record_id = cc.crash_record_id
WHERE cc.road_defect IS NOT NULL
GROUP BY cc.road_defect
ORDER BY total_crashes DESC;
```
La mayorÃ­a de los choques ocurren cuando la vÃ­a no reporta defectos, lo que sugiere que el estado del camino no siempre es el factor principal 

2. Calles con mÃ¡s accidentes

```sql
SELECT
    c.street_name,
    COUNT(*) AS total_crashes
FROM CRASHES c
GROUP BY c.street_name
ORDER BY total_crashes DESC
LIMIT 10;
```
![Calles con mÃ¡s accidentes](figures/calles.png)
Avenidas como Western Ave y Pulaski Rd concentran muchos mÃ¡s choques que el resto

3. ProporciÃ³n de accidentes por condiciÃ³n de iluminaciÃ³n

```sql
SELECT
    cc.lighting_condition,
    COUNT(*) AS total_crashes,
    COUNT(*) * 1.0 / SUM(COUNT(*)) OVER () AS crash_share
FROM crash_circumstances cc
WHERE cc.lighting_condition IS NOT NULL
GROUP BY cc.lighting_condition
ORDER BY crash_share DESC;
```
Donde crash_share representa la proporciÃ³n de accidentes asociada a cada condiciÃ³n de iluminaciÃ³n respecto al total.
![CondiciÃ³n de iluminaciÃ³n](figures/iluminacion.png)
La mayor parte de los accidentes sucede de dÃ­a, porque es cuando mÃ¡s se circula 

### II. Condiciones de clima y fecha
4. Condiciones climÃ¡ticas asociadas a mÃ¡s accidentes

```sql
SELECT 
    cc.weather_condition,
    COUNT(*) AS total_crashes
FROM CRASHES c
JOIN CRASH_CIRCUMSTANCES cc
    ON c.crash_record_id = cc.crash_record_id
GROUP BY cc.weather_condition
ORDER BY total_crashes DESC;
```
![Accidentes por clima](figures/clima_choques.png)
El clima despejado concentra la mayor cantidad de choques, lo cual indica que el mal clima no es la Ãºnica causa de riesgo

5. Severidad de lesiones por condiciÃ³n climÃ¡tica
   
```sql
SELECT
    cc.weather_condition,
    SUM(ci.injuries_fatal) AS fatalities,
    SUM(ci.injuries_incapacitating) AS severe_injuries
FROM CRASHES c
JOIN CRASH_CIRCUMSTANCES cc
    ON c.crash_record_id = cc.crash_record_id
JOIN CRASH_INJURIES ci
    ON c.crash_record_id = ci.crash_record_id
GROUP BY cc.weather_condition
ORDER BY fatalities DESC;
```
En clima despejado es donde se observa el mayor nÃºmero de lesiones graves y fatales, tal vez ppr la alta cantidad de accidentes.

6. Accidentes por dÃ­a de la semana y mes 

```sql
SELECT
    cd.crash_day_of_week,
    cd.crash_month,
    COUNT(*) AS total_crashes
FROM CRASH_DATE cd
GROUP BY cd.crash_day_of_week, cd.crash_month
ORDER BY total_crashes DESC;
```
Los sÃ¡bados en septiembre se concentra la mayor cantidad de choques

7. Horario con mÃ¡s accidentes y lesiones
   
```sql
SELECT
    CASE
      WHEN EXTRACT(HOUR FROM c.incident_date) BETWEEN 0 AND 5  THEN 'Madrugada (0-5)'
      WHEN EXTRACT(HOUR FROM c.incident_date) BETWEEN 6 AND 11 THEN 'MaÃ±ana (6-11)'
      WHEN EXTRACT(HOUR FROM c.incident_date) BETWEEN 12 AND 17 THEN 'Tarde (12-17)'
      ELSE 'Noche (18-23)'
    END AS time_band,
    COUNT(*) AS total_crashes,
    SUM(ci.injuries_fatal
        + ci.injuries_incapacitating
        + ci.injuries_other) AS total_injuries
FROM crashes c
JOIN crash_injuries ci
  ON c.crash_record_id = ci.crash_record_id
GROUP BY time_band
ORDER BY total_injuries DESC;
```
En la tarde, de 12-17, es la que acumula mÃ¡s choques y lesiones, probablemente por tener mayor actividad

### III. Condiciones del conductor
8. Accidentes con alcohol involucrado y severidad del choque

```sql
SELECT
    COUNT(DISTINCT di.person_id) AS drivers_with_alcohol,
    SUM(ci.injuries_fatal) AS fatalities,
    SUM(ci.injuries_incapacitating) AS severe_injuries,
    SUM(ci.injuries_other) AS minor_injuries
FROM driver_info di
JOIN people p
    ON di.person_id = p.person_id
JOIN crash_injuries ci
    ON p.crash_record_id = ci.crash_record_id
WHERE di.bac_result_value > 0;
```
En los choques donde hay alcohol involucrado, se observan tanto muertes como lesiones graves, confirmando que el alcohol sigue siendo un factor de alto riesgo.

9. Edad promedio de conductores en choques con y sin fallecidos

```sql
WITH fatal_flag AS (
	SELECT crash_record_id,
		   CASE WHEN injuries_fatal > 0 THEN 1 ELSE 0 END AS fatal_crash
	FROM crash_injuries
)
SELECT 
	CASE WHEN f.fatal_crash = 1 THEN 'CHOQUE CON FALLECIDOS'
		ELSE 'CHOQUE SIN FALLECIDOS' END AS tipo_choque,
	AVG(p.age) AS avg_driver_age,
	COUNT(*) AS total_drivers
FROM people p
JOIN fatal_flag f USING (crash_record_id)
WHERE p.person_type = 'DRIVER'
GROUP BY f.fatal_crash
ORDER BY avg_driver_age;
```
![Edad de conductores](figures/edad.png)
La edad promedio en ambos casos es aproximadamente 40 aÃ±os, por lo que la edad por sÃ­ sola no parece marcar una gran diferencia

10. Uso de telÃ©fono vs consumo de alcohol

```sql
WITH drivers_alcohol AS (
    SELECT DISTINCT c.crash_record_id
    FROM crashes c
    JOIN people p
        ON c.crash_record_id = p.crash_record_id
    JOIN driver_info di
        ON p.person_id = di.person_id
    WHERE p.person_type = 'DRIVER'
      AND (
            di.bac_result_value > 0
         OR di.physical_condition = 'IMPAIRED - ALCOHOL'
         OR di.physical_condition = 'HAD BEEN DRINKING'
         OR di.physical_condition = 'IMPAIRED - ALCOHOL AND DRUGS'
      )
),
drivers_phone AS (
    SELECT DISTINCT c.crash_record_id
    FROM crashes c
    JOIN people p
        ON c.crash_record_id = p.crash_record_id
    JOIN driver_info di
        ON p.person_id = di.person_id
    WHERE p.person_type = 'DRIVER'
      AND (
            di.cell_phone_use = TRUE
         OR di.driver_action = 'CELL PHONE USE OTHER THAN TEXTING'
         OR di.driver_action = 'TEXTING'
      )
)
SELECT
    (SELECT COUNT(*) FROM drivers_alcohol) AS alcohol_crashes,
    (SELECT COUNT(*) FROM drivers_phone)   AS phone_crashes;
```
![Casos de alcohol vs uso de celular](figures/alcoholvscel.png)
Los choques asociados al alcohol son mÃ¡s frecuentes que los relacionados con el uso del telÃ©fono

### IV. Condiciones del vehÃ­culo
11. LÃ­mite de velocidad

```sql
SELECT
    CASE
      WHEN cc.posted_speed_limit < 30 THEN '<30'
      WHEN cc.posted_speed_limit BETWEEN 30 AND 39 THEN '30â€“39'
      WHEN cc.posted_speed_limit BETWEEN 40 AND 49 THEN '40â€“49'
      WHEN cc.posted_speed_limit BETWEEN 50 AND 59 THEN '50â€“59'
      ELSE '60+'
    END AS speed_band,
    COUNT(*) AS total_crashes,
    SUM(ci.injuries_fatal
        + ci.injuries_incapacitating
        + ci.injuries_other)        AS total_injuries
FROM crash_circumstances cc
JOIN crash_injuries ci
  ON cc.crash_record_id = ci.crash_record_id
GROUP BY speed_band
ORDER BY speed_band DESC;
```
La mayorÃ­a de los choques ocurre en zonas con lÃ­mites de velocidad entre 30 y 39 mph, lo cual no dice mucho porque suelen ser los lÃ­mites mÃ¡s comunes en la ciudad

12. Choques por tipo de uso del vehÃ­culo

```sql
SELECT COALESCE(vs.vehicle_use, 'UNKNOWN') AS vehicle_use, COUNT(DISTINCT v.crash_record_id) AS total_crashes
FROM vehicle v
LEFT JOIN vehicle_specs vs 
ON v.vehicle_id= vs.vehicle_id
GROUP BY vehicle_use
ORDER BY total_crashes DESC;
```
Los vehÃ­culos de uso personal concentran la mayorÃ­a de los choques, muy por encima de vehÃ­culos comerciales o de servicio. 

13. Accidentes por marca y modelo

```sql
SELECT
    v.make,
    v.model,
    COUNT(DISTINCT v.crash_record_id) AS total_crashes
FROM vehicle v
WHERE v.make IS NOT NULL
  AND v.model IS NOT NULL
GROUP BY v.make, v.model
ORDER BY total_crashes DESC
LIMIT 10;
```
![Modelos de vehÃ­culo](figures/modelo.png)
En primer lugar esta Honda Civic, segudio de Toyota Camry y finalmente Honda Accord. Por lo que serÃ­a importante analizar fallas en esos modelos

### V. Hotspots
14. IdentificaciÃ³n de hotspots

```sql
SELECT
    ROUND(latitude::numeric, 3)  AS lat_grid,
    ROUND(longitude::numeric, 3) AS lon_grid,
    COUNT(*) AS total_crashes
FROM crashes
WHERE latitude IS NOT NULL
  AND longitude IS NOT NULL
GROUP BY lat_grid, lon_grid
ORDER BY total_crashes DESC;
```
![Mapa de calor de accidentes](figures/mapacalor.png)
Se ve un hotspot importante en (41.976,-87.905), como se ve en el mapa

15.  Factores dominantes de cada hotspot

```sql
WITH grid AS (
    SELECT
        ROUND(crashes.latitude::numeric, 3)  AS lat_grid,
        ROUND(crashes.longitude::numeric, 3) AS lon_grid,
        crashes.crash_record_id
    FROM crashes crashes
    WHERE crashes.latitude IS NOT NULL
      AND crashes.longitude IS NOT NULL
)
SELECT
    grid.lat_grid,
    grid.lon_grid,
    COUNT(*) AS total_crashes,
    MODE() WITHIN GROUP (ORDER BY crash_circumstances.weather_condition) AS 					most_common_weather,
    MODE() WITHIN GROUP (ORDER BY crash_circumstances.lighting_condition)     AS most_common_lighting,
    MODE() WITHIN GROUP (ORDER BY crash_classification.crash_type)             AS most_common_crash_type
FROM grid 
JOIN crash_circumstances 
  ON grid.crash_record_id = crash_circumstances.crash_record_id
JOIN crash_classification 
  ON grid.crash_record_id = crash_classification.crash_record_id
GROUP BY grid.lat_grid, grid.lon_grid
HAVING COUNT(*) >= 30
ORDER BY total_crashes DESC
LIMIT 30;
```
En el hotspot principal se ven clima despejado y luz del dÃ­a. Por lo que no podemos concluir que estos factores no tienen gran impacto.


# Propuesta de AnÃ¡lisis de Machine Learning: Accidentes de TrÃ¡fico en Chicago

Basado en el esquema relacional (DDL) proporcionado y considerando la segmentaciÃ³n previa por zonas de alta densidad ("Hotspots"), se proponen los siguientes anÃ¡lisis de Machine Learning.

El objetivo general es pasar de un anÃ¡lisis **descriptivo** (quÃ© pasÃ³ y dÃ³nde) a uno **predictivo** (quÃ© pasarÃ¡) y **prescriptivo** (cÃ³mo evitarlo).

---

## 1. PredicciÃ³n de Severidad del Accidente (ClasificaciÃ³n Supervisada)

**Finalidad:**
Determinar la probabilidad de que un choque resulte en lesiones fatales o incapacitantes dadas ciertas condiciones. Esto permite a los servicios de emergencia (911) priorizar recursos y a los planificadores urbanos identificar quÃ© combinaciones de factores (ej. lluvia + noche + exceso de velocidad) son mortales.

### Variables a Utilizar (Features):
* **Temporales (`crash_date`):** `crash_day_of_week`, `crash_month`, y la hora derivada de `incident_date`.
* **Ambientales (`crash_circumstances`):** `weather_condition`, `lighting_condition`, `roadway_surface_cond`.
* **Infraestructura (`crash_circumstances`, `crashes`):** `posted_speed_limit`, `traffic_control_device`, `road_defect`, `alignment`.
* **Vehicular (`vehicle`, `vehicle_models`):** `vehicle_type` (ej. camiÃ³n vs sedÃ¡n), `vehicle_defect`.
* **Humano (`driver_info`, `people`):** `age`, `sex`, `physical_condition`, `bac_result` (nivel de alcohol).
* **Target (Variable Objetivo):** Una variable binaria creada a partir de `crash_injuries`: `0` (Solo daÃ±os materiales) vs `1` (Con heridos/Fatales).

### Modelos Recomendados:
1.  **Random Forest Classifier / XGBoost:** Ideales para manejar datos tabulares con mezcla de variables numÃ©ricas y categÃ³ricas. Permiten extraer la "importancia de las variables" para explicar quÃ© factor pesa mÃ¡s en la gravedad.
2.  **RegresiÃ³n LogÃ­stica:** Ãštil si se busca un modelo altamente interpretable para presentar coeficientes de riesgo (Odds Ratios) a autoridades gubernamentales.

---

## 2. PronÃ³stico de Demanda de Accidentes en Hotspots (Time Series Forecasting)

**Finalidad:**
Predecir la cantidad de accidentes que ocurrirÃ¡n en los "Hotspots" identificados durante la prÃ³xima semana o mes. Esto sirve para la asignaciÃ³n dinÃ¡mica de patrullas o ambulancias en horarios y zonas especÃ­ficas.

### Variables a Utilizar (Features):
* **Serie de Tiempo:** Conteo histÃ³rico de `crash_record_id` agrupado por hora/dÃ­a en cada Hotspot.
* **ExÃ³genas (Externas):**
    * `weather_condition` (PronÃ³stico del clima: si llueve maÃ±ana, Â¿sube el riesgo?).
    * `crash_day_of_week` (Efecto fin de semana).
    * Festivos o eventos especiales (derivados de `incident_date`).

### Modelos Recomendados:
1.  **SARIMA (Seasonal ARIMA):** Para capturar la estacionalidad (ej. picos en horas punta o viernes por la noche).
2.  **Prophet (Facebook):** Muy efectivo para manejar dÃ­as festivos y tendencias estacionales fuertes sin requerir un preprocesamiento exhaustivo.
3.  **LSTM (Long Short-Term Memory - Redes Neuronales):** Si se tiene un volumen de datos histÃ³rico muy grande y se quieren capturar patrones complejos no lineales.

---

## 3. ClasificaciÃ³n de Causa Contribuyente (Multiclass Classification)

**Finalidad:**
Dado un accidente con ciertas caracterÃ­sticas fÃ­sicas (sin saber aÃºn la causa oficial), predecir cuÃ¡l fue el factor detonante (`primary_contributory_cause`). Esto ayuda a validar si la infraestructura vial estÃ¡ induciendo errores (ej. si el modelo predice "Falla en la vÃ­a" basÃ¡ndose en `road_defect` y `lighting_condition`, pero el reporte policial dice "Error del conductor", hay una discrepancia a investigar).

### Variables a Utilizar (Features):
* **Maniobras (`vehicle_maneuvers`):** `maneuver` (ej. giro a la izquierda, cambio de carril).
* **Violaciones (`vehicle_violations`):** `exceed_speed_limit_i`, `cmrc_veh_i`.
* **Entorno:** `trafficway_type`, `intersection_related_i`, `traffic_control_device`.
* **Target:** `crash_classification.primary_contributory_cause` (Esta variable tiene muchas clases, se recomienda agruparlas en 5-6 categorÃ­as principales: DistracciÃ³n, Clima, Infraestructura, Alcohol/Drogas, Exceso de Velocidad).

### Modelos Recomendados:
1.  **Gradient Boosting (LightGBM o CatBoost):** Manejan muy bien variables categÃ³ricas con alta cardinalidad (muchas opciones de texto).
2.  **Decision Trees:** Para generar reglas simples (ej. "Si llueve y es de noche -> Causa probable: Clima").

---

## 4. Clustering de Perfiles de Riesgo (No Supervisado)

**Finalidad:**
Encontrar patrones ocultos dentro de los Hotspots. No todos los accidentes en un Hotspot son iguales. Este anÃ¡lisis agrupa los accidentes en "Tipos" (Clusters).
* *Ejemplo:* Cluster A (Choques leves en hora pico por trÃ¡fico), Cluster B (Choques graves nocturnos por alcohol).

### Variables a Utilizar (Features):
* `posted_speed_limit`
* `age` del conductor.
* `bac_result` (Alcohol).
* `weather_condition`.
* `vehicle_type`.
* `first_crash_type` (Ãngulo, Trasero, PeatÃ³n).

### Modelos Recomendados:
1.  **K-Means / K-Prototypes:** K-Prototypes es esencial aquÃ­ porque permite mezclar variables numÃ©ricas (edad, velocidad) con categÃ³ricas (clima, tipo de vÃ­a).
2.  **DBSCAN:** Para encontrar outliers (accidentes anÃ³malos que no encajan en ningÃºn patrÃ³n comÃºn, posibles fraudes o eventos extraordinarios).

---

## Resumen TÃ©cnico para ImplementaciÃ³n

| AnÃ¡lisis | Tipo de Modelo | Target Principal | Tablas Clave del DDL |
| :--- | :--- | :--- | :--- |
| **Severidad** | ClasificaciÃ³n Binaria | `injuries_fatal` / `incapacitating` | `crashes`, `people`, `crash_injuries` |
| **PronÃ³stico** | RegresiÃ³n / Series de Tiempo | `count(crash_record_id)` | `crashes` (incident_date) |
| **Causas** | ClasificaciÃ³n Multiclase | `primary_contributory_cause` | `crash_classification`, `vehicle_maneuvers` |
| **Perfiles** | Clustering (No supervisado) | N/A | `driver_info`, `crash_circumstances` |

### Notas sobre el Preprocesamiento
Dado el DDL, serÃ¡ necesario realizar **One-Hot Encoding** o **Label Encoding** para las numerosas variables categÃ³ricas (VARCHAR) como `weather_condition`, `lighting_condition` y `trafficway_type` antes de alimentar cualquier modelo numÃ©rico.


## ConclusiÃ³n
El anÃ¡lisis de los datos de accidentes de trÃ¡nsito en Chicago muestra que la ocurrencia de choques no estÃ¡ dominada Ãºnicamente por condiciones adversas como el mal clima o los defectos en la vÃ­a, sino principalmente por factores asociados al volumen de trÃ¡fico, la ubicaciÃ³n y el comportamiento de los conductores. La mayorÃ­a de los accidentes se concentran en condiciones aparentemente favorables â€”clima despejado, buena iluminaciÃ³n y vialidades sin defectosâ€” lo que sugiere que la exposiciÃ³n al trÃ¡fico y la actividad urbana intensa juegan un papel central en el riesgo vial.

Los resultados permiten identificar zonas crÃ­ticas especÃ­ficas, como avenidas con alta concentraciÃ³n de choques (por ejemplo, Western Ave y Pulaski Rd), asÃ­ como patrones temporales claros, especialmente en horarios de alta circulaciÃ³n durante la tarde y en ciertos dÃ­as y meses del aÃ±o. Esto abre la puerta a intervenciones focalizadas en lugar de medidas generales para toda la ciudad.

A partir de estos hallazgos, se proponen las siguientes recomendaciones para disminuir la cantidad y severidad de los choques en Chicago:
1. Intervenciones focalizadas en hotspots
Priorizar mejoras en infraestructura, seÃ±alizaciÃ³n y control vial en las zonas con mayor concentraciÃ³n de accidentes, en lugar de aplicar polÃ­ticas homogÃ©neas en toda la ciudad.
2. GestiÃ³n del trÃ¡fico en horas pico
Implementar estrategias de control de flujo, sincronizaciÃ³n semafÃ³rica y regulaciÃ³n del trÃ¡nsito durante la franja de mayor riesgo (especialmente entre las 12:00 y 17:00 horas).


## ConfiguraciÃ³n y EjecuciÃ³n de la API

A continuaciÃ³n se detallan los pasos necesarios para clonar el repositorio, configurar la conexiÃ³n a la base de datos y ejecutar la API localmente.

### 1. Clonar el repositorio

Abra su terminal y ejecute el siguiente comando para descargar los archivos del proyecto en la direcciÃ³n deseada:

```bash
git clone [https://github.com/alo54/Proyecto-Bases-de-Datos.git](https://github.com/alo54/Proyecto-Bases-de-Datos.git)
```
---

### 2. ConfiguraciÃ³n de la Base de Datos
Para que la API pueda conectarse correctamente a la base de datos PostgreSQL alojada en el servidor (accesible vÃ­a VPN), es necesario actualizar la cadena de conexiÃ³n.

Localice el archivo de configuraciÃ³n de sesiÃ³n en la siguiente ruta: api-proyecto/api-proyecto/db/session.py

Abra el archivo y modifique la variable DATABASE_URL con las credenciales del usuario de prueba:

# Archivo: api-proyecto/api-proyecto/db/session.py

```python
DATABASE_URL = (
    "postgresql+psycopg2://"
    "marco:4igxB7IVPU1WsWIGwZOrSA4gu5wqjo4aAKYkktgtM9i1"
    "@10.10.10.28:5432/traffic_crashes"
)
```
Nota: AsegÃºrese de estar conectado a la VPN privada para tener acceso a la IP 10.10.10.28.

---

### 3. InstalaciÃ³n y EjecuciÃ³n
Este proyecto utiliza uv (Astral) para la gestiÃ³n de dependencias y entornos virtuales. Siga las instrucciones correspondientes a su sistema operativo.
Windows (PowerShell)
```bash
# 1. Navegar al directorio de la API
cd .\Proyecto-Bases-de-Datos\api-proyecto\api-proyecto

# 2. (Opcional) Verificar versiÃ³n de Python
python --version

# 3. Instalar uv (Gestor de paquetes)
irm [https://astral.sh/uv/install.ps1](https://astral.sh/uv/install.ps1) | iex

# 4. Verificar instalaciÃ³n de uv
uv --version

# 5. Crear entorno virtual (basado en .python-version)
uv venv

# 6. Activar el entorno virtual
.\.venv\Scripts\Activate.ps1

# 7. Instalar dependencias (lee pyproject.toml y uv.lock)
uv sync

# 8. Ejecutar la API
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

```bash
macOS / Linux (Bash/Zsh)
# 1. Navegar al directorio de la API
cd ./Proyecto-Bases-de-Datos/api-proyecto/api-proyecto

# 2. (Opcional) Verificar versiÃ³n de Python
python3 --version

# 3. Instalar uv (Gestor de paquetes)
curl -LsSf [https://astral.sh/uv/install.sh](https://astral.sh/uv/install.sh) | sh

# 4. Verificar instalaciÃ³n de uv
uv --version

# 5. Crear entorno virtual (basado en .python-version)
uv venv

# 6. Activar el entorno virtual
source .venv/bin/activate

# 7. Instalar dependencias (lee pyproject.toml y uv.lock)
uv sync

# 8. Ejecutar la API
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Acceso a la API
Una vez que el servidor estÃ© en ejecuciÃ³n, podrÃ¡s acceder a la API y a su documentaciÃ³n interactiva en las siguientes URLs:

API Root: http://localhost:8000

DocumentaciÃ³n (Swagger UI): http://localhost:8000/docs

DocumentaciÃ³n (ReDoc): http://localhost:8000/redoc



## ğŸ”§ SoluciÃ³n de Problemas: Firewall y Puertos
Si la API se estÃ¡ ejecutando pero no logras acceder a ella desde el navegador o herramientas externas, es probable que el Firewall estÃ© bloqueando la conexiÃ³n.

## Windows
Si experimentas bloqueos, asegÃºrate de desactivar los perfiles de Windows Defender (Dominio, Privado y PÃºblico) momentÃ¡neamente para probar la conexiÃ³n.

Alternativamente, puedes ejecutar los siguientes comandos en PowerShell como Administrador para gestionar el puerto especÃ­ficamente:

### Abrir puerto 8000 en el firewall (Permitir trÃ¡fico entrante)
```bash
New-NetFirewallRule -DisplayName "Permitir Puerto 8000" -Direction Inbound -LocalPort 8000 -Protocol TCP -Action Allow
```

### Cerrar puerto 8000 (Revertir cambios)
```bash
Remove-NetFirewallRule -DisplayName "Permitir Puerto 8000"
```
##macOS
En macOS, el sistema suele solicitar permiso para "Aceptar conexiones entrantes" la primera vez que se ejecuta la aplicaciÃ³n. Si esto falla, puedes desactivar el Firewall de aplicaciÃ³n temporalmente desde la terminal:

### Desactivar el Firewall de aplicaciÃ³n (Permitir todas las conexiones)
```bash
sudo /usr/libexec/ApplicationFirewall/socketfilterfw --setglobalstate off
```
### Reactivar el Firewall (Recomendado al finalizar)
```bash
sudo /usr/libexec/ApplicationFirewall/socketfilterfw --setglobalstate on
```
# Arquitectura de la API Traffic Crashes

## Tabla de Contenidos

1. [GeneraciÃ³n de Identificadores Ãšnicos](#generaciÃ³n-de-identificadores-Ãºnicos)
2. [Sistema de ValidaciÃ³n de Datos](#sistema-de-validaciÃ³n-de-datos)
3. [Manejo de Errores y Excepciones](#manejo-de-errores-y-excepciones)
4. [Estructura de los Routers](#estructura-de-los-routers)
5. [Middleware y GestiÃ³n de Sesiones](#middleware-y-gestiÃ³n-de-sesiones)
6. [Logging y Monitoreo](#logging-y-monitoreo)
7. [Mejores PrÃ¡cticas Implementadas](#mejores-prÃ¡cticas-implementadas)

---

## GeneraciÃ³n de Identificadores Ãšnicos

La API implementa tres estrategias distintas de generaciÃ³n de IDs segÃºn la entidad, garantizando unicidad y trazabilidad de los registros.

### 1. Crashes: Hash SHA-512

**UbicaciÃ³n:** `util/id_generators.py :: generate_crash_record_id()`
```python
def generate_crash_record_id(
    incident_date: datetime,
    latitude: float,
    longitude: float,
    street_no: int,
    street_name: str
) -> str:
    """
    Genera un crash_record_id Ãºnico de 128 caracteres usando SHA-512.
    
    Componentes del hash:
    - incident_date (formato ISO: YYYY-MM-DD HH:MM:SS)
    - latitude (truncada a 6 decimales)
    - longitude (truncada a 6 decimales)
    - street_no
    - street_name
    """
```

**Ventajas:**
- **DeterminÃ­stico:** El mismo conjunto de datos siempre produce el mismo ID
- **DetecciÃ³n de duplicados:** Evita registros redundantes automÃ¡ticamente
- **Integridad:** Los 128 caracteres hexadecimales proporcionan una colisiÃ³n prÃ¡cticamente imposible
- **Trazabilidad:** Permite identificar accidentes idÃ©nticos en diferentes cargas de datos

**Ejemplo:**
```python
# Input:
incident_date = "2024-01-15 14:30:00"
latitude = 41.878100
longitude = -87.629800
street_no = 1234
street_name = "N MICHIGAN AVE"

# Output:
crash_record_id = "000013b0123279411e0ec856dae95ab9f0851764350b7feaeb982c7707c6722066910e9391e60f45cec4b7a7a6643eeedb5de39e7245b03447a44c793680dc4b"
```

---

### 2. People: Formato AlfanumÃ©rico Secuencial

**UbicaciÃ³n:** `util/id_generators.py :: generate_person_id()`
```python
def generate_person_id(db: Session) -> str:
    """
    Genera person_id en formato: Q + 7 dÃ­gitos numÃ©ricos con padding de ceros.
    
    Formato: Q0000001, Q0000002, ..., Q9999999
    Capacidad mÃ¡xima: 9,999,999 registros Ãºnicos
    """
```

**ImplementaciÃ³n:**
```sql
-- Query interna para obtener el siguiente nÃºmero
SELECT COALESCE(MAX(CAST(SUBSTRING(person_id FROM 2) AS INTEGER)), 0) + 1 
FROM people 
WHERE person_id ~ '^Q[0-9]{7}$'
```

**CaracterÃ­sticas:**
- **Prefijo identificador:** La letra "Q" distingue visualmente estos IDs de otros tipos
- **Ordenamiento natural:** Los ceros a la izquierda permiten ordenamiento alfanumÃ©rico correcto
- **ValidaciÃ³n incorporada:** La expresiÃ³n regular `^Q[0-9]{7}$` filtra IDs malformados
- **LÃ­mite controlado:** Lanza `ValueError` al alcanzar Q9999999

---

### 3. Vehicle: Autoincremental con BÃºsqueda del MÃ¡ximo

**UbicaciÃ³n:** `util/id_generators.py :: generate_vehicle_id()` y `generate_crash_unit_id()`
```python
def generate_vehicle_id(db: Session) -> int:
    """
    Obtiene el siguiente vehicle_id disponible buscando el mÃ¡ximo actual + 1.
    """
    result = db.execute(text("SELECT COALESCE(MAX(vehicle_id), 0) + 1 FROM vehicle"))
    next_id = result.scalar()
    return next_id
```

**Ventajas sobre SERIAL de PostgreSQL:**
- **Control explÃ­cito:** La aplicaciÃ³n gestiona la secuencia, no la base de datos
- **Portabilidad:** Funciona consistentemente en mÃºltiples motores SQL
- **Debugging simplificado:** Los IDs pueden rastrearse fÃ¡cilmente en logs
- **IntegraciÃ³n con lÃ³gica de negocio:** Permite validaciones previas a la asignaciÃ³n

---

## Sistema de ValidaciÃ³n de Datos

**UbicaciÃ³n:** `util/validators.py`

El mÃ³dulo de validadores implementa una capa de seguridad que previene datos inconsistentes antes de que lleguen a la base de datos.

### Validadores Principales

#### `validate_coordinates(latitude, longitude)`
```python
def validate_coordinates(latitude: float, longitude: float) -> None:
    """
    Valida que las coordenadas estÃ©n dentro de rangos geogrÃ¡ficos vÃ¡lidos.
    
    Reglas:
    - Latitud: -90Â° a 90Â° (Polo Sur a Polo Norte)
    - Longitud: -180Â° a 180Â° (Antimeridiano completo)
    
    Raises:
        HTTPException 400 con mensaje especÃ­fico del rango violado
    """
```

#### `validate_date_not_future(date, field_name)`
Verifica que una fecha no sea posterior al momento actual. Previene registros de accidentes "futuros" por error de entrada.

#### `validate_age(age)`
```python
def validate_age(age: int) -> None:
    """
    Valida que la edad estÃ© en un rango realista (0-120 aÃ±os).
    """
```

#### `validate_vehicle_year(year)`
```python
def validate_vehicle_year(year: int) -> None:
    """
    Valida que el aÃ±o del vehÃ­culo estÃ© entre 1900 y (aÃ±o_actual + 1).
    """
```

#### `validate_foreign_key_exists(db, table_name, column_name, value)`
```python
def validate_foreign_key_exists(
    db: Session,
    table_name: str,
    column_name: str,
    value: Any
) -> None:
    """
    Verifica que una llave forÃ¡nea exista antes de crear el registro.
    
    Ventajas sobre restricciones SQL nativas:
    1. Mensajes de error mÃ¡s descriptivos para el cliente
    2. ValidaciÃ³n temprana antes de transacciones complejas
    3. Logging especÃ­fico de violaciones
    """
```

#### `normalize_boolean(value)`
Convierte representaciones variadas de booleanos a True/False/None:
- Booleanos: `True`, `False`
- NumÃ©ricos: `0` (False), `1` (True)
- Strings: `"true"`, `"false"`, `"1"`, `"0"`, `"yes"`, `"no"` (case-insensitive)

---

## Manejo de Errores y Excepciones

### Arquitectura de Tres Capas
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   1. ValidaciÃ³n Pydantic        â”‚  422 â†’ 400
â”‚   (Transformada en main.py)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   2. Validadores Customizados   â”‚  400
â”‚   (util/validators.py)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   3. Excepciones de Base de     â”‚  400/404/409/500
â”‚      Datos (Routers)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Handler Global de ValidaciÃ³n

**UbicaciÃ³n:** `main.py :: validation_exception_handler()`
```python
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """
    Transforma errores de validaciÃ³n de Pydantic (422) en respuestas 400 Bad Request.
    """
```

**TransformaciÃ³n de errores:**

**Antes (422):**
```json
{
  "detail": [
    {
      "loc": ["body", "latitude"],
      "msg": "ensure this value is greater than or equal to -90",
      "type": "value_error.number.not_ge"
    }
  ]
}
```

**DespuÃ©s (400):**
```json
{
  "detail": "Error de validaciÃ³n en los datos proporcionados",
  "errors": [
    {
      "field": "latitude",
      "message": "Debe ser mayor o igual a -90",
      "type": "greater_than_equal"
    }
  ]
}
```

### CÃ³digos de Estado HTTP Utilizados

| CÃ³digo | Uso | Ejemplo |
|--------|-----|---------|
| **200 OK** | OperaciÃ³n exitosa | GET, PUT exitoso |
| **201 Created** | Recurso creado | POST exitoso |
| **400 Bad Request** | Datos invÃ¡lidos | ValidaciÃ³n fallida
